---
permalink: /
title: '<h2 class="section-header">About me</h2>'
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-149714426-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-149714426-1');
</script>
<div class="about-item">
I am a PhD student at the University of Warwick, UK, focusing on the application of deep generative models in autonomous driving, specifically in the synthesis of camera images and Lidar point clouds. Concurrently, I work as a machine learning researcher in the european union-funded project, Hi-Drive, where I am involved in the development of a semi-automated annotation tool called ML-ADA. <a href='../assets/Hamed_CV.pdf' style="color: #007bff">View my CV for more details.</a>
</div>

<h2 class="section-header">Experience</h2>
<div class="experience">
  <div class="experience-item">
    <h3>ML Engineer (part-time)</h3>
    <p><strong>Hi-Drive</strong>, March 2022 - Feb 2024, Coventry, UK</p>
    <ul>
      <li>&bull; Developed a semi-automatic data annotation tool (ML-ADA) for 2D/3D object detection tasks. ML-ADA resulted in reducing the manual labelling effort in autonomous driving.</li>
      <li>&bull; Designed experiments to approximate the manual annotation effort needed at various levels of automation.</li>
      <li><a class="code" href="https://github.com/hamedhaghighi/ML-assisted-annotation" >code</a></li>
    </ul>
  </div>

  <div class="experience-item">
    <h3>Teaching Assistant</h3>
    <p><strong>University of Warwick</strong>, 2021 - 2024, Coventry, UK
     <ul>
    <li>Machine Intelligence and Data Science (MIDS)</li>
    <li>Dr. Mehrdad Dianati</li>
    </ul>
    </p>
    <ul>
      <li>&bull; Assisted in designing and delivering tutorials for the module, with a focus on implementing fundamental deep learning models using the PyTorch library.</li>
      <li>&bull; Assisted in designing post-module assessments and marking students.</li>
    </ul>
    <p><strong>University of Tehran</strong>,  2017 - 2019, Tehran, Iran
    <ul>
    <li>Pattern Recognition, Computer Vision, Data Analytics</li>
    <li>Dr. Babak Nadjar Aarabi, Dr. Reshad Hosseini, Dr. Mohammad Amin Sadeghi</li>
    </ul>
     </p>
    <ul>
      <li>&bull; Assisted in designing and marking course final projects, as well as grading final exams.</li>
    </ul>
  </div>

  <div class="experience-item">
    <h3>Freelance</h3>
    <p><strong>Collaboration with Dr. Peyman Gifani @ University of Cambridge</strong>, Feb 2020 - May 2020, Remote</p>
    <ul>
      <li>&bull; Successfully reproduced the results of the outstanding <a href="https://www.nature.com/articles/s41467-019-13807-w" target="_blank">paper</a> on generating hit-like molecules from gene-expression using deep generative models.</li>
      <li>&bull; Adapted techniques from <a href="https://arxiv.org/pdf/2002.12826.pdf" target="_blank">Podda <em>et al.</em></a> and <a href="https://pubs.acs.org/doi/epdf/10.1021/acs.jcim.9b00237" target="_blank">Yang <em>et al.</em></a>  to use fragment graphs, a more expressive molecule representation, instead of SMILES. This change resulted in generating more unique and valid molecules.</li>
    </ul>
  </div>

  <div class="experience-item">
    <h3>Summer Intern</h3>
    <p><strong>Medical Image and Signal Processing Research Centre</strong>, Summer 2016, Isfahan, Iran</p>
    <ul>
      <li>&bull; Developed innovative software using image processing techniques to automate the evaluation of crown preparation. This tool is designed to assist students in comparing their crown work against standard parameters during preclinical tooth preparation.</li>
      <li>&bull; Assisted in writing a paper on the evaluation of the software's effectiveness by comparing it with the expert crown preparation. <a href="https://journals.lww.com/jmss/fulltext/2020/10040/Automatic_Evaluation_of_Crown_Preparation_Using.3.aspx" target="_blank">paper link</a></li>
    </ul>
  </div>
</div>


<h2 class="section-header">Education</h2>

<div class="education">
  <div class="education-item">
    <h3>PhD in Engineering</h3>
    <p><strong>University of Warwick</strong>, [2020 - 2024], 
    Coventry, UK</p>
    <ul>
      <li><strong>Thesis</strong>: "Data-driven Simulation of Perception Sensors for Autonomous Vehicles"</li>
    </ul>
  </div>
  
  <div class="education-item">
    <h3>M.Sc. in Artificial Intelligence</h3>
    <p><strong>University of Tehran</strong>, [2016 - 2019], 
    Tehran, Iran</p>
    <ul>
      <li><strong>Thesis</strong>: "Ambient VAE: An Unsupervised Method for Image Restoration"</li>
    </ul>
    <ul>
      <li><strong>GPA</strong>: 18.85/20</li>
    </ul>
  </div>
  
  <div class="education-item">
    <h3>B.Sc. in Software Engineering</h3>
    <p><strong>Isfahan University of Technology</strong>, [2012 - 2016], Isfahan, Iran
    </p>
    <ul>
      <li><strong>GPA</strong>: 17.45/20</li>
    </ul>
  </div>
</div>



<h2 class="section-header">Publications</h2>
<div class="publications">
  <div class="publication-item">
    <h3><a href="https://arxiv.org/abs/2404.05505">Taming Transformers for Realistic Lidar Point Cloud Generation</a></h3>
    <p><em>H. Haghighi, A.Samadi, M. Dianati, V. Donzella and K. Debattista</em>, in arXiv: 2404.05505, 2024</p>
    <a class="code" href="https://github.com/hamedhaghighi/LidarGRIT">Code</a>
  </div>
  
  <div class="publication-item">
    <h3><a href="https://arxiv.org/abs/2312.15817">Contrastive Learning-based Framework for Sim-to-Real Mapping of Lidar Point Clouds in Autonomous Driving Systems</a></h3>
    <p><em>H. Haghighi, A.Samadi, M. Dianati, V. Donzella and K. Debattista</em>, in arXiv: 2312.15817, 2023</p>
    <a class="code" href="https://github.com/hamedhaghighi/CLS2R">Code</a>
  </div>
  
  <div class="publication-item">
    <h3><a href="https://doi.org/10.1109/TITS.2023.3287912">Accelerating Stereo Image Simulation for Automotive Applications Using Neural Stereo Super Resolution</a></h3>
    <p><em>H. Haghighi, M. Dianati, V. Donzella and K. Debattista</em>, IEEE Transaction on Intellignet Transportation Systems, 2023</p>
    <a class="code" href="https://github.com/hamedhaghighi/ETSSR">Code</a>
  </div>
  
  <div class="publication-item">
    <h3><a href="https://arxiv.org/abs/2402.10079">Review of the Learning-based Camera and Lidar Simulation Methods for Autonomous Driving Systems</a></h3>
    <p><em>H. Haghighi, X. Wang, H. Jing, M. Dianati</em>, arXiv: 2402.10079, 2024</p>
  </div>
  
  <div class="publication-item">
    <h3><a href="https://journals.lww.com/jmss/fulltext/2020/10040/Automatic_Evaluation_of_Crown_Preparation_Using.3.aspx">Automatic Evaluation of Crown Preparation using Image Processing Technique: A substitute to Faculty Scoring in Dental Education</a></h3>
    <p><em>Tahani, B.;Rashno, A.;Haghighi, H.; Kafieh, R.</em>, Journal of Medical Signals & Sensors, 2019</p>
  </div>
</div>


<h2 class="section-header">Projects</h2>

<div class="project-grid">
  <div class="project-item" data-link="https://github.com/hamedhaghighi/ML-assisted-annotation">
    <img src="../images/MLADA.jpg" alt="ML-ADA">
    <div class="project-info">
      <p>Developed a semi-automatic data annotation tool (ML-ADA) for 2D/3D object detection tasks in autonomous driving.</p>
    </div>
  </div>

  <div class="project-item" data-link="https://github.com/hamedhaghighi/ML-assisted-annotation">
    <img src="../images/ambient-VAE.png" alt="ML-ADA">
    <div class="project-info">
      <h3>Adapted varational auto-encoders for the unsupervised image restoration task. (MSc thesis)</h3>
    </div>
  </div>
  
  <div class="project-item" data-link="https://github.com/hamedhaghighi/ML-assisted-annotation">
    <img src="../images/UTLC.png" alt="ML-ADA">
    <div class="project-info">
      <p>designed a fast recursive model for lossless image compression using attention mechanism.</p>
    </div>
  </div>

  <div class="project-item" data-link="https://github.com/hamedhaghighi/ML-assisted-annotation">
    <img src="../images/sampleTransformer.png" alt="ML-ADA">
    <div class="project-info">
      <p>Designed a music generative model using an U-Net-based transformer architecture.</p>
    </div>
  </div>

  <div class="project-item" data-link="https://github.com/hamedhaghighi/ML-assisted-annotation">
    <img src="../images/e-puck.png" alt="ML-ADA">
    <div class="project-info">
      <h3>Machine Learning-Assisted Data Annotation (ML-ADA) for 3D/2D Object Detection</h3>
      <p>Implemented particle filter algorithm for real-world problem of E-puck robot localization.</p>
    </div>
  </div>

  <div class="project-item" data-link="https://github.com/hamedhaghighi/ML-assisted-annotation">
    <img src="../images/AECP.jpeg" alt="ML-ADA">
    <div class="project-info">
      <p>Designed and implementated of innovative software for evaluating crown(tooth) preparation.</p>
    </div>
  </div>
</div>








<style>
  .section-header {
  font-size: 2em;
  font-weight: bold;
  color: #333;
  /* background-color: #f5f5f5; */
  padding: 10px 15px;
  border-radius: 5px;
  border-bottom: 2px solid #f2f2f2;
  margin-bottom: 20px;
  text-transform: uppercase;
}

.about-item{

  background-color: #f8f9fa; /* Light background color */
  border-radius: 8px; /* Rounded corners */
  padding: 20px; /* Padding around each item */
  margin-bottom: 30px; /* Spacing between items */
  box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1); /* Shadow for a lifted effect */
}
.project-grid {
  display: grid;
  grid-template-columns: repeat(3, 1fr);
  gap: 20px;
  align-items: stretch;
  background-color: #f8f9fa; /* Light background color */
  border-radius: 8px; /* Rounded corners */
  padding: 20px; /* Padding around each item */
  margin-bottom: 30px; /* Spacing between items */
  box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1); /* Shadow for a lifted effect */
}

.project-item {
  position: relative;
  overflow: hidden;
  cursor: pointer
}

.project-item img {
  width: 100%;
  height: 200px;
  object-fit: cover; /* Maintain aspect ratio */
  transition: transform 0.3s ease-in-out;
  border: 2px solid black; /* Add black border */
}

.project-info {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  background-color: rgba(0, 0, 0, 0.8);
  color: #fff;
  display: flex;
  flex-direction: column;
  justify-content: center;
  align-items: center;
  opacity: 0;
  transition: opacity 0.3s ease-in-out;
}

.project-item:hover img {
  transform: scale(1.1);
}

.project-item:hover .project-info {
  opacity: 1;
}

.project-info h3, .project-info p {
  margin: 10px;
  text-align: center;
}

.project-info p {
  font-size: 14px;
}

/*##############################publication */

.publications {
  margin-bottom: 80px; /* Adjust margin between publications */
}

.publication-item {
  margin-bottom: -30px; /* Adjust margin between items */
  background-color: #f8f9fa; /* Light background color */
  border-radius: 8px; /* Rounded corners */
  padding: 20px; /* Padding around each item */
  margin-bottom: 30px; /* Spacing between items */
  box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1); /* Shadow for a lifted effect */
}

.publication-item h3 {
  margin-bottom: 5px;
}

.publication-item p {
  margin-bottom: 5px;
}

.publication-item a {
  margin-right: 5px;
  text-decoration: none;
  color: #007bff;
}
.code{
  margin-right: 5px;
  text-decoration: none;
  color: #007bff;
  padding-left: 25px; /* Space for GitHub logo */
  background-image: url(../images/git-logo.png); /* GitHub logo as background */
  background-repeat: no-repeat;
  background-size: 20px 20px; /* Size of GitHub logo */
  background-position: left center; /* Position GitHub logo to the left of text */
}
.publication-item a:hover {
  text-decoration: underline;
}

/* ########################education */
.education {
  margin-bottom: 50px;
}

.education-item {
  background-color: #f8f9fa; /* Light background color */
  border-radius: 8px; /* Rounded corners */
  padding: 20px; /* Padding around each item */
  margin-bottom: 30px; /* Spacing between items */
  box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1); /* Shadow for a lifted effect */
}

.education-item h3 {
  margin-bottom: 10px;
  font-size: 1.3em; /* Larger font size for degree */
  color: #000066; /* Degree text color */
}

.education-item p {
  margin-bottom: 15px;
  font-size: 1.1em; /* Font size for university and duration */
}

.education-item ul {
  list-style-type: none; /* Remove bullet points */
  margin-left: 0;
  padding-left: 0;
}

.education-item ul li {
  margin-bottom: 8px;
  font-size: 1em; /* Font size for thesis and GPA */
}

.education-item strong {
  font-weight: bold;
  color: #343a40; /* Text color for strong elements */
}

.education-item .gpa {
  color: #6c757d; /* GPA text color */
  font-size: 0.9em; /* Smaller font size for GPA */
  margin-top: 10px; /* Spacing between university and GPA */
}

/* ########################experience */
.experience {
  margin-bottom: 50px;
}

.experience-item {
  background-color: #f8f9fa; /* Light background color */
  border-radius: 8px; /* Rounded corners */
  padding: 20px; /* Padding around each item */
  margin-bottom: 30px; /* Spacing between items */
  box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1); /* Shadow for a lifted effect */
}

.experience-item h3 {
  margin-bottom: 10px;
  font-size: 1.3em; /* Larger font size for position */
  color: #000066; /* Position text color */
}

.experience-item p {
  margin-bottom: 15px;
  font-size: 1.1em; /* Font size for company, role, and date */
}

.experience-item ul {
  list-style-type: none; /* Remove bullet points */
  margin-left: 0;
  padding-left: 0;
}

.experience-item ul li {
  margin-bottom: 8px;
  font-size: 1em; /* Font size for bullet points */
}

.experience-item strong {
  font-weight: bold;
  color: #343a40; /* Text color for strong elements */
}

.experience-item a {
  color: #007bff; /* Link color */
  text-decoration: none; /* Remove underline */
}

.experience-item a:hover {
  text-decoration: underline; /* Underline on hover */
}

.experience-item em {
  font-style: italic; /* Italic style for author names */
}


</style>

<script>
document.addEventListener('DOMContentLoaded', function() {
  const projectItems = document.querySelectorAll('.project-item');

  projectItems.forEach(item => {
    const link = item.getAttribute('data-link');
    item.addEventListener('click', function() {
      window.location.href = link;
    });
  });
});
</script>